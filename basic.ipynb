{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.framework import constant_op\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import init_ops\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from zipfile import ZipFile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip\n",
      "13574144/13568290 [==============================] - 1s 0us/step\n",
      "13582336/13568290 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "uri = \"https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip\"\n",
    "zip_path = keras.utils.get_file(origin=uri, fname=\"jena_climate_2009_2016.csv.zip\")\n",
    "zip_file = ZipFile(zip_path)\n",
    "zip_file.extractall()\n",
    "csv_path = \"jena_climate_2009_2016.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [\n",
    "    \"Pressure\",\n",
    "    \"Temperature\",\n",
    "    \"Temperature in Kelvin\",\n",
    "    \"Temperature (dew point)\",\n",
    "    \"Relative Humidity\",\n",
    "    \"Saturation vapor pressure\",\n",
    "    \"Vapor pressure\",\n",
    "    \"Vapor pressure deficit\",\n",
    "    \"Specific humidity\",\n",
    "    \"Water vapor concentration\",\n",
    "    \"Airtight\",\n",
    "    \"Wind speed\",\n",
    "    \"Maximum wind speed\",\n",
    "    \"Wind direction in degrees\",\n",
    "]\n",
    "\n",
    "feature_keys = [\n",
    "    \"p (mbar)\",\n",
    "    \"T (degC)\",\n",
    "    \"Tpot (K)\",\n",
    "    \"Tdew (degC)\",\n",
    "    \"rh (%)\",\n",
    "    \"VPmax (mbar)\",\n",
    "    \"VPact (mbar)\",\n",
    "    \"VPdef (mbar)\",\n",
    "    \"sh (g/kg)\",\n",
    "    \"H2OC (mmol/mol)\",\n",
    "    \"rho (g/m**3)\",\n",
    "    \"wv (m/s)\",\n",
    "    \"max. wv (m/s)\",\n",
    "    \"wd (deg)\",\n",
    "]\n",
    "\n",
    "colors = [\n",
    "    \"blue\",\n",
    "    \"orange\",\n",
    "    \"green\",\n",
    "    \"red\",\n",
    "    \"purple\",\n",
    "    \"brown\",\n",
    "    \"pink\",\n",
    "    \"gray\",\n",
    "    \"olive\",\n",
    "    \"cyan\",\n",
    "]\n",
    "\n",
    "date_time_key = \"Date Time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_fraction = 0.715\n",
    "train_split = int(split_fraction * int(df.shape[0]))\n",
    "step = 6\n",
    "\n",
    "past = 720\n",
    "future = 72\n",
    "learning_rate = 0.001\n",
    "batch_size = 256\n",
    "epochs = 10\n",
    "\n",
    "\n",
    "def normalize(data, train_split):\n",
    "    data_mean = data[:train_split].mean(axis=0)\n",
    "    data_std = data[:train_split].std(axis=0)\n",
    "    return (data - data_mean) / data_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The selected parameters are: Pressure, Temperature, Saturation vapor pressure, Vapor pressure deficit, Specific humidity, Airtight, Wind speed\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"The selected parameters are:\",\n",
    "    \", \".join([titles[i] for i in [0, 1, 5, 7, 8, 10, 11]]),\n",
    ")\n",
    "selected_features = [feature_keys[i] for i in [0, 1, 5, 7, 8, 10, 11]]\n",
    "features = df[selected_features]\n",
    "features.index = df[date_time_key]\n",
    "features.head()\n",
    "\n",
    "features = normalize(features.values, train_split)\n",
    "features = pd.DataFrame(features)\n",
    "features.head()\n",
    "\n",
    "train_data = features.loc[0 : train_split - 1]\n",
    "val_data = features.loc[train_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = past + future\n",
    "end = start + train_split\n",
    "\n",
    "x_train = train_data[[i for i in range(7)]].values\n",
    "y_train = features.iloc[start:end][[1]]\n",
    "\n",
    "sequence_length = int(past / step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = keras.preprocessing.timeseries_dataset_from_array(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    sequence_length=sequence_length,\n",
    "    sampling_rate=step,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (256, 120, 7)\n",
      "Target shape: (256, 1)\n"
     ]
    }
   ],
   "source": [
    "x_end = len(val_data) - past - future\n",
    "\n",
    "label_start = train_split + past + future\n",
    "\n",
    "x_val = val_data.iloc[:x_end][[i for i in range(7)]].values\n",
    "y_val = features.iloc[label_start:][[1]]\n",
    "\n",
    "dataset_val = keras.preprocessing.timeseries_dataset_from_array(\n",
    "    x_val,\n",
    "    y_val,\n",
    "    sequence_length=sequence_length,\n",
    "    sampling_rate=step,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "\n",
    "for batch in dataset_train.take(1):\n",
    "    inputs, targets = batch\n",
    "\n",
    "print(\"Input shape:\", inputs.numpy().shape)\n",
    "print(\"Target shape:\", targets.numpy().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with ANN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 120, 7)]          0         \n",
      "                                                                 \n",
      " linear_2 (Linear)           (None, 120, 4)            32        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 120, 1)            5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37\n",
      "Trainable params: 37\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.layers.Input(shape=(inputs.shape[1], inputs.shape[2]))\n",
    "lstm_out = Linear(4)(inputs)\n",
    "outputs = keras.layers.Dense(1)(lstm_out)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss=\"mse\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1172/1172 [==============================] - 10s 8ms/step - loss: 0.4818 - val_loss: 78.2747\n",
      "Epoch 2/10\n",
      "1172/1172 [==============================] - 9s 8ms/step - loss: 0.3956 - val_loss: 81.6294\n",
      "Epoch 3/10\n",
      "1172/1172 [==============================] - 9s 8ms/step - loss: 0.3906 - val_loss: 85.3871\n",
      "Epoch 4/10\n",
      "1172/1172 [==============================] - 9s 8ms/step - loss: 0.3887 - val_loss: 86.5176\n",
      "Epoch 5/10\n",
      "1172/1172 [==============================] - 10s 9ms/step - loss: 0.3878 - val_loss: 86.4181\n",
      "Epoch 6/10\n",
      "1172/1172 [==============================] - 9s 8ms/step - loss: 0.3872 - val_loss: 85.7269\n",
      "Epoch 7/10\n",
      "1172/1172 [==============================] - 9s 8ms/step - loss: 0.3869 - val_loss: 84.7561\n",
      "Epoch 8/10\n",
      "1172/1172 [==============================] - 9s 8ms/step - loss: 0.3866 - val_loss: 83.6640\n",
      "Epoch 9/10\n",
      "1172/1172 [==============================] - 9s 8ms/step - loss: 0.3863 - val_loss: 82.5327\n",
      "Epoch 10/10\n",
      "1172/1172 [==============================] - 9s 8ms/step - loss: 0.3861 - val_loss: 81.4047\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21e8963bf98>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    dataset_train,\n",
    "    epochs=epochs,\n",
    "    validation_data=dataset_val\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 120, 7)]          0         \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               ((None, 120, 4),          192       \n",
      "                              (None, 240, 4))                    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 120, 1)            5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 197\n",
      "Trainable params: 197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.layers.Input(shape=(inputs.shape[1], inputs.shape[2]))\n",
    "lstm_out, _ = LSTM(4)(inputs)\n",
    "outputs = keras.layers.Dense(1)(lstm_out)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss=\"mse\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1172/1172 [==============================] - 12s 10ms/step - loss: 0.5135 - val_loss: 0.3594\n",
      "Epoch 2/10\n",
      "1172/1172 [==============================] - 11s 9ms/step - loss: 0.3864 - val_loss: 0.3645\n",
      "Epoch 3/10\n",
      "1172/1172 [==============================] - 11s 10ms/step - loss: 0.3831 - val_loss: 0.3641\n",
      "Epoch 4/10\n",
      "1172/1172 [==============================] - 11s 9ms/step - loss: 0.3814 - val_loss: 0.3629\n",
      "Epoch 5/10\n",
      "1172/1172 [==============================] - 12s 10ms/step - loss: 0.3801 - val_loss: 0.3618\n",
      "Epoch 6/10\n",
      "1172/1172 [==============================] - 11s 9ms/step - loss: 0.3789 - val_loss: 0.3607\n",
      "Epoch 7/10\n",
      "1172/1172 [==============================] - 11s 9ms/step - loss: 0.3778 - val_loss: 0.3596\n",
      "Epoch 8/10\n",
      "1172/1172 [==============================] - 11s 10ms/step - loss: 0.3768 - val_loss: 0.3587\n",
      "Epoch 9/10\n",
      "1172/1172 [==============================] - 11s 9ms/step - loss: 0.3759 - val_loss: 0.3579\n",
      "Epoch 10/10\n",
      "1172/1172 [==============================] - 11s 9ms/step - loss: 0.3751 - val_loss: 0.3572\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21e896338d0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    dataset_train,\n",
    "    epochs=epochs,\n",
    "    validation_data=dataset_val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 120, 7)]          0         \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               ((None, 120, 4),          248       \n",
      "                              (None, 240, 4))                    \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 120, 1)            5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 253\n",
      "Trainable params: 253\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.layers.Input(shape=(inputs.shape[1], inputs.shape[2]))\n",
    "lstm_out, _ = LSTM(4, trans=True, iters=5)(inputs)\n",
    "outputs = keras.layers.Dense(1)(lstm_out)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss=\"mse\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1172/1172 [==============================] - 18s 15ms/step - loss: 0.5624 - val_loss: 0.3574\n",
      "Epoch 2/10\n",
      "1172/1172 [==============================] - 17s 14ms/step - loss: 0.3912 - val_loss: 0.3646\n",
      "Epoch 3/10\n",
      "1172/1172 [==============================] - 17s 15ms/step - loss: 0.3846 - val_loss: 0.3638\n",
      "Epoch 4/10\n",
      "1172/1172 [==============================] - 17s 15ms/step - loss: 0.3817 - val_loss: 0.3628\n",
      "Epoch 5/10\n",
      "1172/1172 [==============================] - 17s 15ms/step - loss: 0.3799 - val_loss: 0.3619\n",
      "Epoch 6/10\n",
      "1172/1172 [==============================] - 17s 14ms/step - loss: 0.3787 - val_loss: 0.3611\n",
      "Epoch 7/10\n",
      "1172/1172 [==============================] - 17s 15ms/step - loss: 0.3777 - val_loss: 0.3603\n",
      "Epoch 8/10\n",
      "1172/1172 [==============================] - 16s 14ms/step - loss: 0.3770 - val_loss: 0.3595\n",
      "Epoch 9/10\n",
      "1172/1172 [==============================] - 17s 14ms/step - loss: 0.3763 - val_loss: 0.3587\n",
      "Epoch 10/10\n",
      "1172/1172 [==============================] - 17s 14ms/step - loss: 0.3758 - val_loss: 0.3579\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21e8b118b38>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    dataset_train,\n",
    "    epochs=epochs,\n",
    "    validation_data=dataset_val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_19 (InputLayer)       [(None, 120, 7)]          0         \n",
      "                                                                 \n",
      " rru_7 (RRU)                 ((None, 120, 4),          287       \n",
      "                              (None, 120, 4))                    \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 120, 1)            5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 292\n",
      "Trainable params: 292\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.layers.Input(shape=(inputs.shape[1], inputs.shape[2]))\n",
    "lstm_out, _ = RRU(units=4)(inputs)\n",
    "outputs = keras.layers.Dense(1)(lstm_out)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss=\"mse\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1172/1172 [==============================] - 20s 17ms/step - loss: 0.7044 - val_loss: 0.5546\n",
      "Epoch 2/10\n",
      "1172/1172 [==============================] - 20s 17ms/step - loss: 0.5459 - val_loss: 0.5352\n",
      "Epoch 3/10\n",
      "1172/1172 [==============================] - 20s 17ms/step - loss: 0.5315 - val_loss: 0.5196\n",
      "Epoch 4/10\n",
      "1172/1172 [==============================] - 20s 17ms/step - loss: 0.5258 - val_loss: 0.5098\n",
      "Epoch 5/10\n",
      "1172/1172 [==============================] - 20s 17ms/step - loss: 0.5228 - val_loss: 0.5041\n",
      "Epoch 6/10\n",
      "1172/1172 [==============================] - 20s 17ms/step - loss: 0.5207 - val_loss: 0.4994\n",
      "Epoch 7/10\n",
      "1172/1172 [==============================] - 21s 18ms/step - loss: 0.5192 - val_loss: 0.4966\n",
      "Epoch 8/10\n",
      "1172/1172 [==============================] - 20s 17ms/step - loss: 0.5177 - val_loss: 0.4933\n",
      "Epoch 9/10\n",
      "1172/1172 [==============================] - 21s 18ms/step - loss: 0.5164 - val_loss: 0.4905\n",
      "Epoch 10/10\n",
      "1172/1172 [==============================] - 21s 18ms/step - loss: 0.5152 - val_loss: 0.4879\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21e8e82fcf8>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    dataset_train,\n",
    "    epochs=epochs,\n",
    "    validation_data=dataset_val\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Snippet A: Adam Optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.9"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "var1 = tf.Variable(10.0)\n",
    "loss = lambda: (var1 ** 2)/2.0       # d(loss)/d(var1) == var1\n",
    "step_count = opt.minimize(loss, [var1]).numpy()\n",
    "# The first step is `-learning_rate*sign(grad)`\n",
    "var1.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Snippet B: Layer Interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(keras.layers.Layer):\n",
    "    def __init__(self, units=32):\n",
    "        super(Linear, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(\n",
    "            shape=(input_shape[-1], self.units),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            shape=(self.units,), initializer=\"random_normal\", trainable=True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Snippet C: Naive LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "A Naive LSTM Cell Implementation.\n",
    "\n",
    "@link tensorflow/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py#BasicLSTMCell\n",
    "@link https://github.com/piEsposito/pytorch-lstm-by-hand/blob/master/LSTM.ipynb\n",
    "@date MAR-29-2022\n",
    "@note straightforward, in sacrifice of efficiency\n",
    "'''\n",
    "class LSTM(keras.layers.Layer):\n",
    "    def __init__(self, units=32, trans=False, iters=3):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.units = units\n",
    "        self.trans = trans\n",
    "        self.iters = iters\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W_i = self.add_weight(shape=(input_shape[-1], self.units), initializer=\"random_normal\", trainable=True)\n",
    "        self.U_i = self.add_weight(shape=(self.units, self.units), initializer=\"random_normal\", trainable=True)\n",
    "        self.b_i = self.add_weight(shape=(self.units, ), initializer=\"random_normal\", trainable=True)\n",
    "\n",
    "        self.W_f = self.add_weight(shape=(input_shape[-1], self.units), initializer=\"random_normal\", trainable=True)\n",
    "        self.U_f = self.add_weight(shape=(self.units, self.units), initializer=\"random_normal\", trainable=True)\n",
    "        self.b_f = self.add_weight(shape=(self.units, ), initializer=\"random_normal\", trainable=True)\n",
    "\n",
    "        self.W_c = self.add_weight(shape=(input_shape[-1], self.units), initializer=\"random_normal\", trainable=True)\n",
    "        self.U_c = self.add_weight(shape=(self.units, self.units), initializer=\"random_normal\", trainable=True)\n",
    "        self.b_c = self.add_weight(shape=(self.units, ), initializer=\"random_normal\", trainable=True)\n",
    "\n",
    "        self.W_o = self.add_weight(shape=(input_shape[-1], self.units), initializer=\"random_normal\", trainable=True)\n",
    "        self.U_o = self.add_weight(shape=(self.units, self.units), initializer=\"random_normal\", trainable=True)\n",
    "        self.b_o = self.add_weight(shape=(self.units, ), initializer=\"random_normal\", trainable=True)\n",
    "\n",
    "        if self.trans:\n",
    "            self.Q   = self.add_weight(shape=(self.units, input_shape[-1]), initializer=\"random_normal\", trainable=True)\n",
    "            self.R   = self.add_weight(shape=(input_shape[-1], self.units), initializer=\"random_normal\", trainable=True)\n",
    "\n",
    "    def mogrigy(self, x_t, h_t):\n",
    "        sigmoid = math_ops.sigmoid\n",
    "        for i in range(1, self.iters + 1):\n",
    "            if (i % 2 == 0):\n",
    "                h_t = (2 * sigmoid(x_t @ self.R)) * h_t\n",
    "            else:\n",
    "                x_t = (2 * sigmoid(h_t @ self.Q)) * x_t\n",
    "        return x_t, h_t\n",
    "\n",
    "    def call(self, inputs, init_states=None):\n",
    "        bs = inputs.shape[1]\n",
    "        one = constant_op.constant(1, dtype=dtypes.int32)\n",
    "        sigmoid = math_ops.sigmoid\n",
    "        tanh = math_ops.tanh\n",
    "        if init_states is None:\n",
    "            h_t, c_t = (\n",
    "                tf.zeros((bs, self.units)),\n",
    "                tf.zeros((bs, self.units)),\n",
    "            )\n",
    "        else:\n",
    "            h_t, c_t = array_ops.split(value=init_states, num_or_size_splits=2, axis=one)\n",
    "\n",
    "        x_t = inputs\n",
    "\n",
    "        if self.trans:\n",
    "            x_t, h_t = self.mogrigy(x_t, h_t)\n",
    "\n",
    "        i_t = sigmoid(x_t @ self.W_i + h_t @ self.U_i + self.b_i)\n",
    "        f_t = sigmoid(x_t @ self.W_f + h_t @ self.U_f + self.b_f)\n",
    "        g_t = tanh(x_t @ self.W_c + h_t @ self.U_c + self.b_c)\n",
    "        o_t = sigmoid(x_t @ self.W_o + h_t @ self.U_o + self.b_o)\n",
    "        c_t = f_t * c_t + i_t * g_t\n",
    "        h_t = o_t * tanh(c_t)\n",
    "            \n",
    "        new_state = array_ops.concat([h_t, c_t], 1)\n",
    "        return h_t, new_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Snippet D Residual Recurrent Unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RRU(keras.layers.Layer):\n",
    "    def __init__(self, units=32, q=1.0, dropout_rate=0.5):\n",
    "        super(RRU, self).__init__()\n",
    "        self.n = units\n",
    "        self.p = 1\n",
    "        self.q = q\n",
    "        self.dropout_rate = dropout_rate\n",
    "    \n",
    "    def instance_norm(self, cur):\n",
    "        variance = tf.reduce_mean(tf.square(cur), [-1], keepdims=True)\n",
    "        cur = cur * tf.math.rsqrt(variance + 1e-6)\n",
    "        return cur\n",
    "    \n",
    "    def inv_sigmoid(self, y):\n",
    "        return np.log(y / (1 - y))\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.m = input_shape[-1]\n",
    "        self.g = round(self.q * (self.m + self.n))\n",
    "\n",
    "        self.W_x = self.add_weight(shape=(self.m, self.g), initializer=\"random_normal\", trainable=True)\n",
    "        self.W_h = self.add_weight(shape=(self.n, self.g), initializer=\"random_normal\", trainable=True)\n",
    "        self.B_j = self.add_weight(shape=(self.g,       ), initializer=tf.zeros_initializer(), trainable=True)\n",
    "\n",
    "        self.W_k = self.add_weight(shape=(self.g, self.g), initializer=\"random_normal\", trainable=True)\n",
    "        self.B_k = self.add_weight(shape=(self.g,       ), initializer=tf.zeros_initializer(), trainable=True)\n",
    "\n",
    "        self.W_c = self.add_weight(shape=(self.g, self.p), initializer=\"random_normal\", trainable=True)\n",
    "        self.B_c = self.add_weight(shape=(self.n,       ), initializer=tf.zeros_initializer(), trainable=True)\n",
    "\n",
    "        # self.W_o = self.add_weight(shape=(self.g, self.n), initializer=\"random_normal\", trainable=True)\n",
    "        # self.B_o = self.add_weight(shape=(self.p,       ), initializer=tf.zeros_initializer(), trainable=True)\n",
    "\n",
    "        self.S = self.add_weight(shape=(self.n,       ), initializer=init_ops.constant_initializer(self.inv_sigmoid(np.random.uniform(0.01, 0.99, size=self.n)) / self.q), trainable=True)\n",
    "        self.Z = self.add_weight(shape=(self.n,       ), initializer=tf.zeros_initializer(), trainable=True)\n",
    "\n",
    "    def call(self, inputs, init_states=None):\n",
    "        bs = inputs.shape[1]\n",
    "        sigmoid = math_ops.sigmoid\n",
    "        relu = tf.nn.relu\n",
    "        dropout = tf.nn.dropout\n",
    "        if init_states is None:\n",
    "            h_t = tf.zeros((bs, self.n))\n",
    "        else:\n",
    "            h_t = init_states\n",
    "        x_t = inputs\n",
    "        j = relu(self.instance_norm(x_t @ self.W_x + h_t @ self.W_h + self.B_j))\n",
    "        j = relu(j @ self.W_k + self.B_k)\n",
    "        d = dropout(j, rate=self.dropout_rate)\n",
    "        c = d @ self.W_c + self.B_c\n",
    "        h_t = h_t * sigmoid(self.S) + c * self.Z\n",
    "        # o_t = d @ self.W_o + self.B_o\n",
    "        return h_t, h_t"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c26b10e94c62085fc47affa68e83b97a20faa7df4bd67b84d9f35c79618f4dfd"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.framework import constant_op\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from zipfile import ZipFile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip\n",
      "13574144/13568290 [==============================] - 1s 0us/step\n",
      "13582336/13568290 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "uri = \"https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip\"\n",
    "zip_path = keras.utils.get_file(origin=uri, fname=\"jena_climate_2009_2016.csv.zip\")\n",
    "zip_file = ZipFile(zip_path)\n",
    "zip_file.extractall()\n",
    "csv_path = \"jena_climate_2009_2016.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [\n",
    "    \"Pressure\",\n",
    "    \"Temperature\",\n",
    "    \"Temperature in Kelvin\",\n",
    "    \"Temperature (dew point)\",\n",
    "    \"Relative Humidity\",\n",
    "    \"Saturation vapor pressure\",\n",
    "    \"Vapor pressure\",\n",
    "    \"Vapor pressure deficit\",\n",
    "    \"Specific humidity\",\n",
    "    \"Water vapor concentration\",\n",
    "    \"Airtight\",\n",
    "    \"Wind speed\",\n",
    "    \"Maximum wind speed\",\n",
    "    \"Wind direction in degrees\",\n",
    "]\n",
    "\n",
    "feature_keys = [\n",
    "    \"p (mbar)\",\n",
    "    \"T (degC)\",\n",
    "    \"Tpot (K)\",\n",
    "    \"Tdew (degC)\",\n",
    "    \"rh (%)\",\n",
    "    \"VPmax (mbar)\",\n",
    "    \"VPact (mbar)\",\n",
    "    \"VPdef (mbar)\",\n",
    "    \"sh (g/kg)\",\n",
    "    \"H2OC (mmol/mol)\",\n",
    "    \"rho (g/m**3)\",\n",
    "    \"wv (m/s)\",\n",
    "    \"max. wv (m/s)\",\n",
    "    \"wd (deg)\",\n",
    "]\n",
    "\n",
    "colors = [\n",
    "    \"blue\",\n",
    "    \"orange\",\n",
    "    \"green\",\n",
    "    \"red\",\n",
    "    \"purple\",\n",
    "    \"brown\",\n",
    "    \"pink\",\n",
    "    \"gray\",\n",
    "    \"olive\",\n",
    "    \"cyan\",\n",
    "]\n",
    "\n",
    "date_time_key = \"Date Time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_fraction = 0.715\n",
    "train_split = int(split_fraction * int(df.shape[0]))\n",
    "step = 6\n",
    "\n",
    "past = 720\n",
    "future = 72\n",
    "learning_rate = 0.001\n",
    "batch_size = 256\n",
    "epochs = 10\n",
    "\n",
    "\n",
    "def normalize(data, train_split):\n",
    "    data_mean = data[:train_split].mean(axis=0)\n",
    "    data_std = data[:train_split].std(axis=0)\n",
    "    return (data - data_mean) / data_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The selected parameters are: Pressure, Temperature, Saturation vapor pressure, Vapor pressure deficit, Specific humidity, Airtight, Wind speed\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"The selected parameters are:\",\n",
    "    \", \".join([titles[i] for i in [0, 1, 5, 7, 8, 10, 11]]),\n",
    ")\n",
    "selected_features = [feature_keys[i] for i in [0, 1, 5, 7, 8, 10, 11]]\n",
    "features = df[selected_features]\n",
    "features.index = df[date_time_key]\n",
    "features.head()\n",
    "\n",
    "features = normalize(features.values, train_split)\n",
    "features = pd.DataFrame(features)\n",
    "features.head()\n",
    "\n",
    "train_data = features.loc[0 : train_split - 1]\n",
    "val_data = features.loc[train_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = past + future\n",
    "end = start + train_split\n",
    "\n",
    "x_train = train_data[[i for i in range(7)]].values\n",
    "y_train = features.iloc[start:end][[1]]\n",
    "\n",
    "sequence_length = int(past / step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = keras.preprocessing.timeseries_dataset_from_array(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    sequence_length=sequence_length,\n",
    "    sampling_rate=step,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (256, 120, 7)\n",
      "Target shape: (256, 1)\n"
     ]
    }
   ],
   "source": [
    "x_end = len(val_data) - past - future\n",
    "\n",
    "label_start = train_split + past + future\n",
    "\n",
    "x_val = val_data.iloc[:x_end][[i for i in range(7)]].values\n",
    "y_val = features.iloc[label_start:][[1]]\n",
    "\n",
    "dataset_val = keras.preprocessing.timeseries_dataset_from_array(\n",
    "    x_val,\n",
    "    y_val,\n",
    "    sequence_length=sequence_length,\n",
    "    sampling_rate=step,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "\n",
    "for batch in dataset_train.take(1):\n",
    "    inputs, targets = batch\n",
    "\n",
    "print(\"Input shape:\", inputs.numpy().shape)\n",
    "print(\"Target shape:\", targets.numpy().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with ANN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 120, 7)]          0         \n",
      "                                                                 \n",
      " linear_1 (Linear)           (None, 120, 32)           256       \n",
      "                                                                 \n",
      " dense (Dense)               (None, 120, 1)            33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 289\n",
      "Trainable params: 289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.layers.Input(shape=(inputs.shape[1], inputs.shape[2]))\n",
    "lstm_out = Linear(32)(inputs)\n",
    "outputs = keras.layers.Dense(1)(lstm_out)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss=\"mse\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1172/1172 [==============================] - 14s 11ms/step - loss: 0.4197 - val_loss: 103.1771\n",
      "Epoch 2/10\n",
      "1172/1172 [==============================] - 13s 11ms/step - loss: 0.3982 - val_loss: 100.0180\n",
      "Epoch 3/10\n",
      "1172/1172 [==============================] - 13s 11ms/step - loss: 0.3939 - val_loss: 94.9508\n",
      "Epoch 4/10\n",
      "1172/1172 [==============================] - 13s 11ms/step - loss: 0.3917 - val_loss: 90.0621\n",
      "Epoch 5/10\n",
      "1172/1172 [==============================] - 14s 12ms/step - loss: 0.3905 - val_loss: 83.9553\n",
      "Epoch 6/10\n",
      "1172/1172 [==============================] - 13s 11ms/step - loss: 0.3896 - val_loss: 82.5686\n",
      "Epoch 7/10\n",
      "1172/1172 [==============================] - 13s 11ms/step - loss: 0.3889 - val_loss: 83.9479\n",
      "Epoch 8/10\n",
      "1172/1172 [==============================] - 14s 12ms/step - loss: 0.3881 - val_loss: 81.4972\n",
      "Epoch 9/10\n",
      "1172/1172 [==============================] - 13s 11ms/step - loss: 0.3877 - val_loss: 80.9430\n",
      "Epoch 10/10\n",
      "1172/1172 [==============================] - 14s 12ms/step - loss: 0.3872 - val_loss: 82.0827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21e824713c8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    dataset_train,\n",
    "    epochs=epochs,\n",
    "    validation_data=dataset_val\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 120, 7)]          0         \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               ((None, 120, 32),         5120      \n",
      "                              (None, 240, 32))                   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 120, 1)            33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,153\n",
      "Trainable params: 5,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.layers.Input(shape=(inputs.shape[1], inputs.shape[2]))\n",
    "lstm_out, _ = LSTM(32)(inputs)\n",
    "outputs = keras.layers.Dense(1)(lstm_out)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss=\"mse\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1172/1172 [==============================] - 37s 31ms/step - loss: 0.4462 - val_loss: 0.3664\n",
      "Epoch 2/10\n",
      "1172/1172 [==============================] - 38s 32ms/step - loss: 0.3845 - val_loss: 0.3641\n",
      "Epoch 3/10\n",
      "1172/1172 [==============================] - 36s 31ms/step - loss: 0.3834 - val_loss: 0.3624\n",
      "Epoch 4/10\n",
      "1172/1172 [==============================] - 36s 31ms/step - loss: 0.3825 - val_loss: 0.3614\n",
      "Epoch 5/10\n",
      "1172/1172 [==============================] - 36s 31ms/step - loss: 0.3817 - val_loss: 0.3606\n",
      "Epoch 6/10\n",
      "1172/1172 [==============================] - 37s 32ms/step - loss: 0.3809 - val_loss: 0.3598\n",
      "Epoch 7/10\n",
      "1172/1172 [==============================] - 39s 33ms/step - loss: 0.3802 - val_loss: 0.3592\n",
      "Epoch 8/10\n",
      "1172/1172 [==============================] - 38s 33ms/step - loss: 0.3794 - val_loss: 0.3586\n",
      "Epoch 9/10\n",
      "1172/1172 [==============================] - 39s 33ms/step - loss: 0.3787 - val_loss: 0.3581\n",
      "Epoch 10/10\n",
      "1172/1172 [==============================] - 36s 31ms/step - loss: 0.3781 - val_loss: 0.3575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21e84323a90>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    dataset_train,\n",
    "    epochs=epochs,\n",
    "    validation_data=dataset_val\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Snippet A: Adam Optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.9"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "var1 = tf.Variable(10.0)\n",
    "loss = lambda: (var1 ** 2)/2.0       # d(loss)/d(var1) == var1\n",
    "step_count = opt.minimize(loss, [var1]).numpy()\n",
    "# The first step is `-learning_rate*sign(grad)`\n",
    "var1.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Snippet B: Layer Interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(keras.layers.Layer):\n",
    "    def __init__(self, units=32):\n",
    "        super(Linear, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(\n",
    "            shape=(input_shape[-1], self.units),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            shape=(self.units,), initializer=\"random_normal\", trainable=True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Snippet C: Naive LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "A Naive LSTM Cell Implementation.\n",
    "\n",
    "@link tensorflow/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py#BasicLSTMCell\n",
    "@link https://github.com/piEsposito/pytorch-lstm-by-hand/blob/master/LSTM.ipynb\n",
    "@date MAR-29-2022\n",
    "@note straightforward, in sacrifice of efficiency\n",
    "'''\n",
    "class LSTM(keras.layers.Layer):\n",
    "    def __init__(self, units=32):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W_i = self.add_weight(shape=(input_shape[-1], self.units), initializer=\"random_normal\", trainable=True)\n",
    "        self.U_i = self.add_weight(shape=(self.units, self.units), initializer=\"random_normal\", trainable=True)\n",
    "        self.b_i = self.add_weight(shape=(self.units, ), initializer=\"random_normal\", trainable=True)\n",
    "\n",
    "        self.W_f = self.add_weight(shape=(input_shape[-1], self.units), initializer=\"random_normal\", trainable=True)\n",
    "        self.U_f = self.add_weight(shape=(self.units, self.units), initializer=\"random_normal\", trainable=True)\n",
    "        self.b_f = self.add_weight(shape=(self.units, ), initializer=\"random_normal\", trainable=True)\n",
    "\n",
    "        self.W_c = self.add_weight(shape=(input_shape[-1], self.units), initializer=\"random_normal\", trainable=True)\n",
    "        self.U_c = self.add_weight(shape=(self.units, self.units), initializer=\"random_normal\", trainable=True)\n",
    "        self.b_c = self.add_weight(shape=(self.units, ), initializer=\"random_normal\", trainable=True)\n",
    "\n",
    "        self.W_o = self.add_weight(shape=(input_shape[-1], self.units), initializer=\"random_normal\", trainable=True)\n",
    "        self.U_o = self.add_weight(shape=(self.units, self.units), initializer=\"random_normal\", trainable=True)\n",
    "        self.b_o = self.add_weight(shape=(self.units, ), initializer=\"random_normal\", trainable=True)\n",
    "\n",
    "    def call(self, inputs, init_states=None):\n",
    "        bs = inputs.shape[1]\n",
    "        one = constant_op.constant(1, dtype=dtypes.int32)\n",
    "        sigmoid = math_ops.sigmoid\n",
    "        tanh = math_ops.tanh\n",
    "        if init_states is None:\n",
    "            h_t, c_t = (\n",
    "                tf.zeros((bs, self.units)),\n",
    "                tf.zeros((bs, self.units)),\n",
    "            )\n",
    "        else:\n",
    "            h_t, c_t = array_ops.split(value=init_states, num_or_size_splits=2, axis=one)\n",
    "\n",
    "        x_t = inputs\n",
    "\n",
    "        i_t = sigmoid(x_t @ self.W_i + h_t @ self.U_i + self.b_i)\n",
    "        f_t = sigmoid(x_t @ self.W_f + h_t @ self.U_f + self.b_f)\n",
    "        g_t = tanh(x_t @ self.W_c + h_t @ self.U_c + self.b_c)\n",
    "        o_t = sigmoid(x_t @ self.W_o + h_t @ self.U_o + self.b_o)\n",
    "        c_t = f_t * c_t + i_t * g_t\n",
    "        h_t = o_t * tanh(c_t)\n",
    "            \n",
    "        new_state = array_ops.concat([h_t, c_t], 1)\n",
    "        return h_t, new_state"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c26b10e94c62085fc47affa68e83b97a20faa7df4bd67b84d9f35c79618f4dfd"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

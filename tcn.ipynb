{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Convolutional Network (2017)\n",
    "\n",
    "S. Bai, J. Z. Kolter, and V. Koltun, “An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling,” arXiv:1803.01271 [cs], Apr. 2018, Accessed: Apr. 14, 2022. [Online]. Available: http://arxiv.org/abs/1803.01271<br/>\n",
    "\n",
    "TCN = 1D FCN + Causal Convolution<br/>\n",
    "\n",
    "- Causal Convolution\n",
    "- Dilation Convolution\n",
    "- Residual Connection\n",
    "\n",
    "![avatar](img/tcn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, Dropout, Layer\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "\n",
    "from zipfile import ZipFile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 12, 32])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# * 探索代码\n",
    "'''\n",
    "每个batch      4个mini batch\n",
    "每个mini batch 128个数据行\n",
    "每个数据行      10个点\n",
    "'''\n",
    "input_shape = (4, 10, 128)\n",
    "x = tf.random.normal(input_shape)\n",
    "y = CausalConv1D(filters=32, kernel_size=3, dilation_rate=1)(x)\n",
    "padding = tf.constant([[0, 0], [3-1, 0], [0, 0]])\n",
    "tf.pad(y, padding).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 时间序列预测\n",
    "master_url_root = \"https://raw.githubusercontent.com/numenta/NAB/master/data/\"\n",
    "\n",
    "df_small_noise_url_suffix = \"artificialNoAnomaly/art_daily_small_noise.csv\"\n",
    "df_small_noise_url = master_url_root + df_small_noise_url_suffix\n",
    "df_small_noise = pd.read_csv(\n",
    "    df_small_noise_url, parse_dates=True, index_col=\"timestamp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = df_small_noise.values\n",
    "input_data = values[:-10]\n",
    "targets = values[10:]\n",
    "dataset_train = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "    input_data, targets, sequence_length=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (128, 32, 1)\n",
      "Target shape: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "for batch in dataset_train.take(1):\n",
    "    inputs, targets = batch\n",
    "\n",
    "print(\"Input shape:\", inputs.numpy().shape)\n",
    "print(\"Target shape:\", targets.numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_27 (InputLayer)       [(None, 32, 1)]           0         \n",
      "                                                                 \n",
      " tcn_24 (TCN)                (None, 32, 1)             54        \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32, 1)             2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56\n",
      "Trainable params: 56\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.layers.Input(shape=(32,1))\n",
    "tcn_out = TCN([1, 1, 1])(inputs)\n",
    "outputs = keras.layers.Dense(1)(tcn_out)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.05), loss=\"mse\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "32/32 [==============================] - 2s 25ms/step - loss: 2285.9053 - val_loss: 680.6572\n",
      "Epoch 2/32\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 715.6017 - val_loss: 240.7920\n",
      "Epoch 3/32\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 281.3766 - val_loss: 176.5928\n",
      "Epoch 4/32\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 203.1738 - val_loss: 159.5183\n",
      "Epoch 5/32\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 178.2701 - val_loss: 155.2338\n",
      "Epoch 6/32\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 169.7629 - val_loss: 154.5621\n",
      "Epoch 7/32\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 164.4594 - val_loss: 154.0522\n",
      "Epoch 8/32\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 162.3778 - val_loss: 153.9573\n",
      "Epoch 9/32\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 161.1022 - val_loss: 153.9952\n",
      "Epoch 10/32\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 159.7736 - val_loss: 153.9401\n",
      "Epoch 11/32\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 159.2984 - val_loss: 153.9685\n",
      "Epoch 12/32\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 158.6255 - val_loss: 153.8578\n",
      "Epoch 13/32\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 158.1157 - val_loss: 153.8167\n",
      "Epoch 14/32\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 158.1530 - val_loss: 153.7117\n",
      "Epoch 15/32\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 158.0021 - val_loss: 153.7442\n",
      "Epoch 16/32\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 157.8046 - val_loss: 153.7857\n",
      "Epoch 17/32\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 157.3758 - val_loss: 153.5947\n",
      "Epoch 18/32\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 157.4641 - val_loss: 153.4963\n",
      "Epoch 19/32\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 157.6802 - val_loss: 153.4456\n",
      "Epoch 20/32\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 157.8591 - val_loss: 153.4723\n",
      "Epoch 21/32\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 157.0586 - val_loss: 153.1598\n",
      "Epoch 22/32\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 156.9450 - val_loss: 152.9967\n",
      "Epoch 23/32\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 156.8971 - val_loss: 152.7426\n",
      "Epoch 24/32\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 156.6941 - val_loss: 152.4161\n",
      "Epoch 25/32\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 156.3159 - val_loss: 151.9719\n",
      "Epoch 26/32\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 155.6922 - val_loss: 151.2365\n",
      "Epoch 27/32\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 155.9965 - val_loss: 150.6809\n",
      "Epoch 28/32\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 154.8031 - val_loss: 149.5582\n",
      "Epoch 29/32\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 154.2712 - val_loss: 148.3956\n",
      "Epoch 30/32\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 153.8605 - val_loss: 147.0777\n",
      "Epoch 31/32\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 152.5256 - val_loss: 145.4930\n",
      "Epoch 32/32\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 151.8331 - val_loss: 143.7738\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d65c050208>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    dataset_train,\n",
    "    epochs=32,\n",
    "    validation_data=dataset_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义参数\n",
    "NUMBER_OF_COLUMNS = 2048"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因果卷积层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalConv1D(Conv1D):\n",
    "    def __init__(self, kernel_size, dilation_rate, filters):\n",
    "        super(CausalConv1D, self).__init__(\n",
    "            filters      = filters,\n",
    "            kernel_size  = kernel_size,\n",
    "            dilation_rate= dilation_rate\n",
    "        )\n",
    "    def call(self, inputs):\n",
    "        padding = (self.kernel_size[0] - 1) * self.dilation_rate[0]\n",
    "        inputs = tf.pad(inputs, tf.constant([(0, 0,), (1, 0), (0, 0)]) * padding)\n",
    "        return super(CausalConv1D, self).call(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TCN块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalBlock(Layer):\n",
    "    def __init__(self, kernel_size, dilation_rate, dropout=0.2, n_outputs=1):\n",
    "        super(TemporalBlock, self).__init__()        \n",
    "        self.dropout = dropout\n",
    "        self.n_outputs = n_outputs\n",
    "        self.conv1 = CausalConv1D(\n",
    "            kernel_size=kernel_size,\n",
    "            dilation_rate=dilation_rate,\n",
    "            filters=n_outputs)\n",
    "        self.conv2 = CausalConv1D(\n",
    "            kernel_size=kernel_size,\n",
    "            dilation_rate=dilation_rate,\n",
    "            filters=n_outputs)\n",
    "        self.down_sample = None\n",
    "\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.dropout1 = Dropout(self.dropout)\n",
    "        self.dropout2 = Dropout(self.dropout)\n",
    "        # channel_dim = 2\n",
    "        # if input_shape[channel_dim] != self.n_outputs:\n",
    "        #     self.down_sample = tf.layers.Dense(self.n_outputs, activation=None)\n",
    "    \n",
    "    def call(self, inputs, training=True):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.dropout1(x, training=training)\n",
    "        x = self.conv2(x)\n",
    "        x = self.dropout2(x, training=training)\n",
    "        # if self.down_sample is not None:\n",
    "        #     inputs = self.down_sample(inputs)\n",
    "        return tf.nn.relu(x + inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCN(Layer):\n",
    "    def __init__(self, num_channels, kernel_size=8, dropout=0.2):\n",
    "        super(TCN, self).__init__()\n",
    "        self.layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            out_channels = num_channels[i]\n",
    "            self.layers.append(\n",
    "                TemporalBlock(\n",
    "                    n_outputs=out_channels, \n",
    "                    kernel_size=kernel_size, \n",
    "                    dilation_rate=dilation_size,\n",
    "                    dropout=dropout)\n",
    "            )\n",
    "    \n",
    "    def call(self, inputs, training=True):\n",
    "        outputs = inputs\n",
    "        for layer in self.layers:\n",
    "            outputs = layer(outputs, training=training)\n",
    "        return outputs"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c26b10e94c62085fc47affa68e83b97a20faa7df4bd67b84d9f35c79618f4dfd"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
